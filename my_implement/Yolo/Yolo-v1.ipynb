{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo-v1的pytorch实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照yolov1.cfg、yolov1原论文、[github上一份pytorch实现](https://github.com/ProgrammerZhujinming/YOLOv1/blob/main/YOLO_V1_Model.py)；\n",
    "\n",
    "yolov1.cfg最后的fc层内容没太看懂；\n",
    "\n",
    "module.py是方便fine-tune的版本；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试填充函数：\n",
    "- 输入的tensor：（batch，channel，height， width）\n",
    "- 填充pad：[宽左，宽右，高上，高下]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4, 4]),\n",
       " tensor([[[[-2.3467, -0.8221, -2.6249,  0.4169],\n",
       "           [ 0.1475,  1.1148,  0.3720,  0.2368],\n",
       "           [-0.4836,  0.3655,  1.1565, -0.4798],\n",
       "           [-0.2914, -1.6210,  0.9042,  0.5888]]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 4, 4))\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 11, 7]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000, -2.3467, -0.8221, -2.6249,  0.4169,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.1475,  1.1148,  0.3720,  0.2368,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.4836,  0.3655,  1.1565, -0.4798,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.2914, -1.6210,  0.9042,  0.5888,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = F.pad(x, pad=[1,2,3,4])\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 11, 7]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000, -2.3467, -0.8221, -2.6249,  0.4169,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.1475,  1.1148,  0.3720,  0.2368,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.4836,  0.3655,  1.1565, -0.4798,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.2914, -1.6210,  0.9042,  0.5888,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = nn.ZeroPad2d([1,2,3,4])\n",
    "y = f(x)\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = y[0, 0, 0, :4]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然这个自适应padding形状的函数没用上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_padding_shape(input_shape, kernel_size, stride):\n",
    "    '''\n",
    "    根据输入形状和步长，自动计算合适的padding_shape，以保持卷积过后，形状不变\n",
    "    \n",
    "    返回list[int]，[宽左，宽右，高上，高下]，为零填充的像素数\n",
    "    '''\n",
    "    padding=[]\n",
    "    height, width = input_shape\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_h, kernel_w = kernel_size, kernel_size\n",
    "    else:\n",
    "        kernel_h, kernel_w = kernel_size\n",
    "    if isinstance(stride, int):\n",
    "        stride_h, stride_w = stride, stride\n",
    "    else:\n",
    "        stride_h, stride_w = stride\n",
    "    \n",
    "    # 宽，(width - kernel_w + padding_w_left + padding_w_right) / stride_w + 1 == width\n",
    "    padding.append(((width-1)*stride_w - width + kernel_w) / 2)             # 整除，取下整\n",
    "    if ((width-1)*stride_w - width + kernel_w) % 2 == 0:\n",
    "        padding.append(((width-1)*stride_w - width + kernel_w) / 2)\n",
    "    else:\n",
    "        padding.append(((width-1)*stride_w - width + kernel_w) / 2 + 1)\n",
    "    # 高，也是类似\n",
    "    padding.append(((height-1)*stride_h - height + kernel_h) / 2)\n",
    "    if ((height-1)*stride_h - height + kernel_h) % 2 == 0:\n",
    "        padding.append(((height-1)*stride_h - height + kernel_h) / 2)\n",
    "    else:\n",
    "        padding.append(((height-1)*stride_h - height + kernel_h) / 2 + 1)\n",
    "    \n",
    "    return padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络中重复结构（卷积层）的构建函数，启发于VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_layer(in_channels, out_channels, kernel_size, stride, padding, batch_normalize=1, activation='leaky'):\n",
    "    '''\n",
    "    构建yolov1中的卷积层, 形如pad->conv2d->batch_norm->activation function\n",
    "    \n",
    "    Parameters:\n",
    "    - in_channels, out_channels, kernel_size, stride, padding: 同nn.Conv2d\n",
    "    - batch_normalize: 是否要做批量归一化, 默认要做\n",
    "    - activation: 激活函数种类, 默认LeakyReLU\n",
    "    '''\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding))\n",
    "    if batch_normalize:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "    if activation=='leaky':\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络结构如图，图源自原论文，网络输入形如(batch_size, channel, height, width)\n",
    "\n",
    "<img src='./figs/yolov1_model.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中7x7代表将图片均匀划分成7x7个grid cell，每个grid cell负责判断是否有物体的中心点落在上面：\n",
    "\n",
    "<img src='./figs/yolov1_grid.png' style='zoom:50%'>\n",
    "\n",
    "每个grid对应一个长度为（5xB + class num）的向量：\n",
    "\n",
    "- B为每个grid负责回归的边界框个数；\n",
    "- 每个grid只能取B个中最好的一个作为预测值，即网络最多只能预测SxS个物体，论文中S=7，这也是YOLO-V1对小物体、密集物体效果不好的原因；\n",
    "- 5：每个边界框$(x_c, y_c, w, h, c)$，中心点位置、高宽、置信度（该box负责预测物体）；\n",
    "- class num：后面跟的ont hot向量，表示在该box负责预测物体的条件下，预测为类别i的条件概率（有疑问）；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v1(nn.Module):\n",
    "    '''\n",
    "    Yolo-v1的pytorch实现\n",
    "    \n",
    "    输入形状为448x448, B为每个grid预测的个数, Class_Num为分类数\n",
    "    '''\n",
    "    def __init__(self, B=2, Classes_Num=20):\n",
    "        super().__init__()\n",
    "        self.B = B\n",
    "        self.Classes_Num = Classes_Num\n",
    "        # 提前padding，保持各个块的卷积过后，形状不变；\n",
    "        # in:3x448x448, out:64x112x112\n",
    "        self.blk1 = nn.Sequential(\n",
    "            *create_conv_layer(3, 64, kernel_size=7, stride=2, padding=3),  # stride=2的conv和pool都是减高宽的\n",
    "            # nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=2),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:64x112x112, out:192x56x56\n",
    "        self.blk2 = nn.Sequential(\n",
    "            *create_conv_layer(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(192),\n",
    "            # nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:192x56x56, out:512x28x28\n",
    "        self.blk3 = nn.Sequential(\n",
    "            *create_conv_layer(192, 128, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(256, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:512x28x28, out:1024x14x14\n",
    "        self.blk4 = nn.Sequential(\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:1024x14x14, out:1024x14x14\n",
    "        self.blk4 = nn.Sequential(\n",
    "            *create_conv_layer(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        # in:1024x14x14, out:1024x7x7\n",
    "        self.blk5 = nn.Sequential(\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        # in:7x7x1024, out:7x7x30\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 1024, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 7 * 7 * (B*5 + Classes_Num)),\n",
    "            nn.Sigmoid()        # 增加sigmoid函数是为了将输出全部映射到(0,1)之间，因为如果出现负数或太大的数，后续计算loss会很麻烦\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 类GoogLeNet\n",
    "        # 也可换成resnet50，删除stage5后的全局池化和全连接层，增加一个带有空洞卷积的网络block（模仿detnet网络，增加感受野而不改变输出特征图大小）\n",
    "        x = self.blk1(x)\n",
    "        x = self.blk2(x)\n",
    "        x = self.blk3(x)\n",
    "        x = self.blk4(x)\n",
    "        # 后四层卷积\n",
    "        x = self.blk5(x)\n",
    "        # 为方便后处理，需要将输出构建成7x7x30，而不是30x7x7；为了符合直觉，需要做重排列将特征放在最后一维\n",
    "        # (batch_size, channel, height, width) -> (batch_size, height, width, channel)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # 展平+全连接层\n",
    "        x = self.fc(x)\n",
    "        # 重构\n",
    "        x = x.view((-1, 7, 7, (self.B*5 + self.Classes_Num)))\n",
    "\n",
    "    def initialize_params(self):\n",
    "        '''网络参数初始化'''\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "疑问：(x,y,w,h,c)和p是否需要做softmax？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function:\n",
    "\n",
    "<img src='./figs/yolov1_loss.png' style='zoom:60%;' />\n",
    "\n",
    "- 掩码：\n",
    "  - $\\mathbb{1}_{i}^{obj}$：有gt bbox的中心点落在grid $i$中；\n",
    "  - $\\mathbb{1}_{ij}^{obj}$：有gt bbox的中心点落在grid $i$中，且该grid回归的的B个bbox中，第$j$个bbox与该gt bbox的IoU最大；\n",
    "  - $\\mathbb{1}_{ij}^{noobj} == not \\ (\\mathbb{1}_{ij}^{obj})$；\n",
    "- 第一项为中心点定位误差；\n",
    "- 第二项为宽高定位误差：\n",
    "  - 求根号可使小的bbox对误差更敏感；\n",
    "- 第三、四项为confidence回归误差：\n",
    "  - $\\mathbb{1}_{ij}^{obj}==1$时（第三项），$\\hat{C}_i$为该grid回归的第j个bbox，与中心点落在该grid的gt bbox的IoU；\n",
    "  - $\\mathbb{1}_{ij}^{obj}==0$时（第四项），$\\hat{C}_i$为0；\n",
    "  - $C_i$为预测值；\n",
    "- 第五项为类别预测误差；\n",
    "- 权重：\n",
    "  - 物体检测问题，是一个典型的类别数目不均衡的问题。其中49个格点，含有物体的格点往往只有3、4个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的mAP不会太高，因为模型更倾向于不含有物体的格点。\n",
    "  - $\\lambda_{\\mathbb{coord}}$：使网络更重视$(x_c,y_c,w,h)$的预测；\n",
    "  - $\\lambda_{noobj}$：对不负责预测obj的confidence loss，赋予小的权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v1_loss(nn.Module):\n",
    "    '''\n",
    "    Yolo-v1的损失函数计算的pytorch实现\n",
    "\n",
    "    Parameters:\n",
    "    - img_shape: _size_2_t, [h, w]\n",
    "    - S: _size_2_t, 表示一张图片被划分成了[高x宽]个grid, 默认为7表示7x7\n",
    "    - B: int, 一个grid回归多少个bbox\n",
    "    - Class_num: int, 类别个数\n",
    "    - l_coord、l_noobj: 对应两个lambda\n",
    "    '''\n",
    "    def __init__(self, img_shape=448, S=7, B=2, Class_num=20, l_coord=5, l_noobj=0.5):\n",
    "        super().__init__()\n",
    "        # 图片的形状\n",
    "        if isinstance(img_shape, int):\n",
    "            self.img_h = img_shape\n",
    "            self.img_w = img_shape\n",
    "        elif hasattr(img_shape, '__iter__'):\n",
    "            self.img_h = img_shape[0]\n",
    "            self.img_w = img_shape[1]\n",
    "        # 网格的个数形状\n",
    "        if isinstance(S, int):\n",
    "            self.S_h = S\n",
    "            self.S_w = S\n",
    "        elif hasattr(S, '__iter__'):\n",
    "            self.S_h = S[0]\n",
    "            self.S_w = S[1]\n",
    "        self.grid_h = self.img_h / self.S_h     # 网格的高度和宽度\n",
    "        self.grid_w = self.img_w / self.S_w\n",
    "        self.B = B\n",
    "        self.Class_num = Class_num\n",
    "        self.l_coord = l_coord\n",
    "        self.l_noobj = l_noobj\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        '''\n",
    "        前向计算\n",
    "        - pred:  (batch_size, S_h, S_w, (B)*5+Class_num), 未经过预处理, 仍然只是Yolo_v1输出的sigmoid\n",
    "        - gt:    (batch_size, S_h, S_w, 5+Class_num), 已经经过预处理, 框成center形式(但中心点位置是相对于左上角的), 其中confidence代表1_i^{obj}, 类别成one-hot\n",
    "        '''\n",
    "        # 定义三个计算损失的变量 正样本定位损失 样本置信度损失 样本类别损失\n",
    "        loss_coord = 0\n",
    "        loss_confidence = 0\n",
    "        loss_classes = 0\n",
    "        iou_sum = 0\n",
    "        object_num = 0\n",
    "\n",
    "        mseLoss = nn.MSELoss()\n",
    "        # pred的预处理\n",
    "        for i in range(self.B):\n",
    "            pred[:, :, :, i*5+0] = pred[:, :, :, i*5+0] * self.grid_w   # x_c相对于grid左上角的位置，最大不能超过一个grid\n",
    "            pred[:, :, :, i*5+1] = pred[:, :, :, i*5+1] * self.grid_h   # y_c相对于grid左上角的位置\n",
    "            pred[:, :, :, i*5+2] = pred[:, :, :, i*5+2] * self.img_w    # w，最大不能超过整张图片\n",
    "            pred[:, :, :, i*5+3] = pred[:, :, :, i*5+3] * self.img_h    # h\n",
    "        \n",
    "        # loss计算\n",
    "        # 其实也可以使用矩阵运算优化，但保险起见，还是用了循环\n",
    "        for batch in range(len(pred)):\n",
    "            for row in range(self.S_h):\n",
    "                for col in range(self.S_w):\n",
    "                    pred_ = pred[batch, row, col, :]\n",
    "                    gt_ = gt[batch, row, col, :]\n",
    "                    if gt_[4] == 0:\n",
    "                        # [row, col]处的grid，没有gt框中心落在这，故B个框都是负样本，只需要加置信度loss\n",
    "                        for i in range(self.B):\n",
    "                            loss_confidence += self.l_noobj * torch.pow(pred_[i*5 + 4], 2)\n",
    "                    else:\n",
    "                        # [row, col]处的grid，有gt框中心落在这\n",
    "                        object_num += 1\n",
    "                        # 分别计算回归的B个框与gt的IoU\n",
    "                        iou = torch.zeros(self.B)\n",
    "                        gt_bbox = utils.bbox_center_to_corner(gt_[:4])\n",
    "                        for i in range(self.B):\n",
    "                            pred_bbox = utils.bbox_center_to_corner(pred_[i*5:(i*5+4)])\n",
    "                            iou[i] = utils.IoU(pred_bbox, gt_bbox)\n",
    "                        # 取IoU最大的成为正样本，其它B-1个成为负样本\n",
    "                        val, idx = iou.topk(1)\n",
    "                        # 定位loss\n",
    "                        loss_coord += self.l_coord * (torch.pow(pred_[idx*5] - gt_[0], 2) + torch.pow(pred_[idx*5+1] - gt_[1], 2)) + \\\n",
    "                                      self.l_coord * (torch.pow(torch.sqrt(pred_[idx*5+2]) - torch.sqrt(gt_[2]), 2) + \\\n",
    "                                                      torch.pow(torch.sqrt(pred_[idx*5+3]) - torch.sqrt(gt_[3]), 2))\n",
    "                        # 置信度loss\n",
    "                        iou_sum += val\n",
    "                        for i in range(self.B):\n",
    "                            if i == idx:\n",
    "                                # 正样本\n",
    "                                loss_confidence += torch.pow(pred_[i*5 + 4] - val, 2)\n",
    "                            else:\n",
    "                                # 负样本\n",
    "                                loss_confidence += self.l_noobj * torch.pow(pred_[i*5 + 4], 2)\n",
    "                        # 类别预测loss\n",
    "                        gt_class = gt_[5:]\n",
    "                        pred_class = pred_[(self.B*5):]\n",
    "                        loss_classes += mseLoss(gt_class, pred_class)\n",
    "        loss_coord /= len(pred)\n",
    "        loss_confidence /= len(pred)\n",
    "        loss_classes /= len(pred)\n",
    "        loss = loss_coord + loss_confidence + loss_classes\n",
    "        return loss, loss_coord, loss_confidence, loss_classes, iou_sum, object_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、预测阶段后处理：非极大值抑制（NMS）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不应用于训练阶段，只应用于训练完成后，应用模型进行预测的阶段。\n",
    "\n",
    "非极大值抑制（Non-Maximum Suppression）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先，对每个grid cell负责的B个框，该box负责预测物体的置信度 * 该box负责预测物体的条件下是各个类别的条件概率\n",
    "  - 获得形如$S_h * S_w * B * ClassNum$的全概率，和形如$S_h * S_w * B * 4$的center格式的2D框；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2, 1, 1, 2, 1, 1, 2, 3, 1, 2, 3, 3, 3, 1, 2, 1, 3, 3, 1, 2, 1, 1, 2,\n",
       "           1, 1, 3, 3, 2, 2, 2],\n",
       "          [3, 1, 2, 3, 2, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 3, 1, 1, 2, 2, 3, 1,\n",
       "           2, 3, 1, 3, 2, 2, 3]],\n",
       "\n",
       "         [[3, 3, 3, 2, 1, 1, 1, 2, 3, 3, 2, 3, 3, 3, 3, 3, 1, 3, 2, 1, 1, 1, 1,\n",
       "           1, 2, 2, 3, 3, 3, 1],\n",
       "          [2, 1, 3, 2, 1, 1, 2, 3, 3, 1, 3, 3, 3, 1, 2, 1, 1, 3, 3, 1, 1, 3, 1,\n",
       "           2, 2, 1, 1, 1, 3, 2]]],\n",
       "\n",
       "\n",
       "        [[[3, 3, 2, 3, 1, 2, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 3, 2, 3, 2, 2, 1,\n",
       "           1, 3, 3, 1, 3, 2, 1],\n",
       "          [1, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 3, 1, 3, 1, 1, 3, 3, 1, 3, 2, 2, 1,\n",
       "           1, 1, 3, 2, 1, 2, 2]],\n",
       "\n",
       "         [[3, 1, 3, 3, 2, 2, 2, 1, 1, 3, 3, 3, 1, 3, 2, 1, 2, 3, 2, 3, 1, 2, 2,\n",
       "           3, 1, 1, 2, 1, 3, 3],\n",
       "          [1, 3, 1, 2, 1, 3, 3, 3, 1, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 1, 2, 2, 1,\n",
       "           2, 3, 2, 1, 2, 3, 1]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(1, 4, (2, 2, 2, 30))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5475, 0.2880, 0.0404],\n",
       "          [0.6104, 0.8349, 0.4260]],\n",
       "\n",
       "         [[0.4481, 0.5095, 0.0212],\n",
       "          [0.5301, 0.8102, 0.4951]]],\n",
       "\n",
       "\n",
       "        [[[0.3969, 0.3484, 0.7428],\n",
       "          [0.4144, 0.3333, 0.5826]],\n",
       "\n",
       "         [[0.9589, 0.2530, 0.0824],\n",
       "          [0.2324, 0.0358, 0.3401]]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z = torch.split(a, [1, 3, 26], dim=-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5475, 0.2880, 0.0404],\n",
       "           [0.6104, 0.8349, 0.4260]],\n",
       " \n",
       "          [[0.4481, 0.5095, 0.0212],\n",
       "           [0.5301, 0.8102, 0.4951]]],\n",
       " \n",
       " \n",
       "         [[[0.3969, 0.3484, 0.7428],\n",
       "           [0.4144, 0.3333, 0.5826]],\n",
       " \n",
       "          [[0.9589, 0.2530, 0.0824],\n",
       "           [0.2324, 0.0358, 0.3401]]]]),\n",
       " tensor([0.5475, 0.2880, 0.0404, 0.6104, 0.8349, 0.4260, 0.4481, 0.5095, 0.0212,\n",
       "         0.5301, 0.8102, 0.4951, 0.3969, 0.3484, 0.7428, 0.4144, 0.3333, 0.5826,\n",
       "         0.9589, 0.2530, 0.0824, 0.2324, 0.0358, 0.3401]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 1, 2],\n",
      "          [1, 2, 3]],\n",
      "\n",
      "         [[3, 3, 2],\n",
      "          [1, 3, 2]]],\n",
      "\n",
      "\n",
      "        [[[3, 2, 3],\n",
      "          [3, 3, 3]],\n",
      "\n",
      "         [[1, 3, 3],\n",
      "          [3, 1, 2]]]])\n",
      "tensor([[0, 0, 0],\n",
      "        [1, 2, 3],\n",
      "        [3, 3, 2],\n",
      "        [1, 3, 2],\n",
      "        [3, 2, 3],\n",
      "        [3, 3, 3],\n",
      "        [1, 3, 3],\n",
      "        [3, 1, 2]])\n",
      "tensor([[[[1, 1, 2],\n",
      "          [1, 2, 3]],\n",
      "\n",
      "         [[3, 3, 2],\n",
      "          [1, 3, 2]]],\n",
      "\n",
      "\n",
      "        [[[3, 2, 3],\n",
      "          [3, 3, 3]],\n",
      "\n",
      "         [[1, 3, 3],\n",
      "          [3, 1, 2]]]])\n",
      "tensor([[0, 0, 0],\n",
      "        [1, 2, 3],\n",
      "        [3, 3, 2],\n",
      "        [1, 3, 2],\n",
      "        [3, 2, 3],\n",
      "        [3, 3, 3],\n",
      "        [1, 3, 3],\n",
      "        [3, 1, 2]])\n",
      "tensor([[[[0, 0, 0],\n",
      "          [1, 2, 3]],\n",
      "\n",
      "         [[3, 3, 2],\n",
      "          [1, 3, 2]]],\n",
      "\n",
      "\n",
      "        [[[3, 2, 3],\n",
      "          [3, 3, 3]],\n",
      "\n",
      "         [[1, 3, 3],\n",
      "          [3, 1, 2]]]])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "b = y.flatten(0, -2)\n",
    "c = copy.deepcopy(y.flatten(0, -2))\n",
    "print(y)\n",
    "c[0] = 0\n",
    "print(c)\n",
    "print(y)\n",
    "b[0] = 0\n",
    "print(b)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMS(YOLO_pred, img_shape=448, S=7, B=2, Class_Num=20, threshold_confidence=0.5, threshold_IOU=0.5):\n",
    "    '''\n",
    "    非极大值抑制\n",
    "    - YOLO_pred: (batch_size, S_h, S_w, B*5+Class_Num)形状的张量\n",
    "    - threshold_confidence: 抹去低置信度的阈值\n",
    "    - threshold_IOU: 抹去高交并比的阈值\n",
    "    '''\n",
    "    # 参数计算\n",
    "    if isinstance(img_shape, int):\n",
    "        img_h = img_shape\n",
    "        img_w = img_shape\n",
    "    elif hasattr(img_shape, '__iter__'):\n",
    "        img_h = img_shape[0]\n",
    "        img_w = img_shape[1]\n",
    "    ## 网格的个数形状\n",
    "    if isinstance(S, int):\n",
    "        S_h = S\n",
    "        S_w = S\n",
    "    elif hasattr(S, '__iter__'):\n",
    "        S_h = S[0]\n",
    "        S_w = S[1]\n",
    "    grid_h = img_h / S_h     # 网格的高度和宽度\n",
    "    grid_w = img_w / S_w\n",
    "    \n",
    "    # 在最后一维上拆分YOLO_pred\n",
    "    split_list = []\n",
    "    for _ in range(B):\n",
    "        split_list.append(5)\n",
    "    split_list.append(Class_Num)\n",
    "    sp = torch.split(YOLO_pred, split_list, dim=-1)\n",
    "    # 构建batch_size * (S_h * S_w * B) * (4+Class_Num)的2D框和全概率矩阵\n",
    "    import copy\n",
    "    mats = []\n",
    "    for i in range(B):\n",
    "        box = copy.deepcopy(sp[i].flatten(1, -2))           # 框\n",
    "        conf = copy.deepcopy(sp[-1].flatten(1, -2))         # 预测各个类别的条件概率\n",
    "        # 将2D框中心点，从相对grid cell左上角的位置的归一化，处理成图片中的位置\n",
    "        for j in range(S_w):\n",
    "            for k in range(S_h):\n",
    "                idx = k*S_h+j\n",
    "                box[:, idx, 0] = (box[:, idx, 0] + j) * grid_w      # x_c\n",
    "                box[:, idx, 1] = (box[:, idx, 1] + k) * grid_h      # y_c\n",
    "        box[:, :, 2] = box[:, :, 2] * img_w    # w，最大不能超过整张图片\n",
    "        box[:, :, 3] = box[:, :, 3] * img_h    # h\n",
    "        conf[:] = conf * box[:, :, -1].reshape(box.shape[0], box.shape[1], 1)\n",
    "        mats.append(torch.concat([utils.bbox_center_to_corner(box[:, :, :-1]), conf], dim=-1))\n",
    "    return torch.concat(mats, dim=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4351, 0.6799, 0.8972, 0.4421, 0.2097, 0.9547, 0.7884, 0.7919,\n",
       "           0.1581, 0.8927, 0.4051, 0.1783, 0.7054, 0.4133, 0.5562, 0.4997,\n",
       "           0.9275, 0.7859, 0.4626, 0.6801, 0.0267, 0.8003, 0.8136, 0.6262,\n",
       "           0.4043, 0.6691, 0.2075, 0.6883, 0.0826, 0.4966],\n",
       "          [0.2771, 0.8550, 0.0710, 0.3983, 0.9381, 0.2124, 0.9591, 0.4795,\n",
       "           0.4430, 0.5980, 0.2625, 0.1037, 0.9449, 0.2599, 0.3231, 0.1672,\n",
       "           0.8706, 0.2201, 0.5999, 0.1432, 0.2071, 0.3969, 0.6297, 0.2425,\n",
       "           0.9052, 0.5778, 0.1951, 0.4210, 0.7238, 0.6170]],\n",
       "\n",
       "         [[0.8478, 0.9829, 0.7557, 0.4279, 0.6505, 0.3034, 0.9449, 0.0644,\n",
       "           0.4493, 0.4324, 0.5263, 0.0706, 0.4483, 0.9468, 0.7306, 0.3038,\n",
       "           0.6460, 0.7360, 0.0820, 0.1826, 0.3659, 0.0381, 0.0646, 0.4737,\n",
       "           0.6519, 0.9730, 0.4153, 0.8049, 0.3359, 0.8801],\n",
       "          [0.3956, 0.1897, 0.0141, 0.8776, 0.2809, 0.9450, 0.0906, 0.3798,\n",
       "           0.1822, 0.9221, 0.6515, 0.1074, 0.5085, 0.3016, 0.5383, 0.4594,\n",
       "           0.9303, 0.7008, 0.0514, 0.0818, 0.3408, 0.1891, 0.6200, 0.4434,\n",
       "           0.4246, 0.1460, 0.6883, 0.1828, 0.6675, 0.9451]]],\n",
       "\n",
       "\n",
       "        [[[0.5701, 0.0032, 0.8163, 0.5130, 0.1636, 0.8115, 0.6434, 0.6748,\n",
       "           0.7507, 0.3497, 0.5767, 0.2436, 0.3017, 0.2706, 0.8539, 0.3938,\n",
       "           0.3085, 0.3065, 0.7787, 0.9406, 0.7077, 0.7323, 0.3756, 0.8391,\n",
       "           0.1442, 0.2496, 0.9129, 0.5986, 0.9164, 0.1864],\n",
       "          [0.1432, 0.0216, 0.8424, 0.2480, 0.5111, 0.6587, 0.9741, 0.2943,\n",
       "           0.3381, 0.2421, 0.5294, 0.6770, 0.3155, 0.4480, 0.4038, 0.9537,\n",
       "           0.5249, 0.6338, 0.8082, 0.0640, 0.0051, 0.5528, 0.1055, 0.0920,\n",
       "           0.9537, 0.7442, 0.8995, 0.4435, 0.7321, 0.7203]],\n",
       "\n",
       "         [[0.3289, 0.3564, 0.5357, 0.5912, 0.6924, 0.1030, 0.0615, 0.4291,\n",
       "           0.2844, 0.1075, 0.9904, 0.5099, 0.5386, 0.8794, 0.6775, 0.1306,\n",
       "           0.2039, 0.3505, 0.2997, 0.0168, 0.7327, 0.9390, 0.9961, 0.6932,\n",
       "           0.4279, 0.3574, 0.3093, 0.7735, 0.3994, 0.8462],\n",
       "          [0.5457, 0.8998, 0.1356, 0.8121, 0.2608, 0.8232, 0.9997, 0.1741,\n",
       "           0.5429, 0.3771, 0.9465, 0.5223, 0.4921, 0.7039, 0.8416, 0.5986,\n",
       "           0.6538, 0.1368, 0.9029, 0.2730, 0.3058, 0.8071, 0.9541, 0.1682,\n",
       "           0.0823, 0.6301, 0.1746, 0.9033, 0.7414, 0.6169]]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((2, 2, 2, 30))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 4, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMS(a, S=2)[:, :4].shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88474ca0ac5bd289cfc2b7cff5e070fc2eb64be0b001ce0011ec337ea9a55b21"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
