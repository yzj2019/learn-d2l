{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo-v1的pytorch实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照yolov1.cfg、yolov1原论文、[github上一份pytorch实现](https://github.com/ProgrammerZhujinming/YOLOv1/blob/main/YOLO_V1_Model.py)；\n",
    "\n",
    "yolov1.cfg最后的fc层内容没太看懂；\n",
    "\n",
    "module.py是方便fine-tune的版本；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试填充函数：\n",
    "- 输入的tensor：（batch，channel，height， width）\n",
    "- 填充pad：[宽左，宽右，高上，高下]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4, 4]),\n",
       " tensor([[[[-0.8737, -0.3453, -0.0878, -0.3545],\n",
       "           [-0.7838, -1.0773, -1.8497, -0.1728],\n",
       "           [-1.2762,  0.7853,  1.8007,  1.3618],\n",
       "           [-0.0407,  0.9483,  1.7208,  1.1484]]]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 1, 4, 4))\n",
    "x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 11, 7]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.8737, -0.3453, -0.0878, -0.3545,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.7838, -1.0773, -1.8497, -0.1728,  0.0000,  0.0000],\n",
       "           [ 0.0000, -1.2762,  0.7853,  1.8007,  1.3618,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.0407,  0.9483,  1.7208,  1.1484,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = F.pad(x, pad=[1,2,3,4])\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 11, 7]),\n",
       " tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.8737, -0.3453, -0.0878, -0.3545,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.7838, -1.0773, -1.8497, -0.1728,  0.0000,  0.0000],\n",
       "           [ 0.0000, -1.2762,  0.7853,  1.8007,  1.3618,  0.0000,  0.0000],\n",
       "           [ 0.0000, -0.0407,  0.9483,  1.7208,  1.1484,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = nn.ZeroPad2d([1,2,3,4])\n",
    "y = f(x)\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = y[0, 0, 0, :4]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然这个自适应padding形状的函数没用上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_padding_shape(input_shape, kernel_size, stride):\n",
    "    '''\n",
    "    根据输入形状和步长，自动计算合适的padding_shape，以保持卷积过后，形状不变\n",
    "    \n",
    "    返回list[int]，[宽左，宽右，高上，高下]，为零填充的像素数\n",
    "    '''\n",
    "    padding=[]\n",
    "    height, width = input_shape\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_h, kernel_w = kernel_size, kernel_size\n",
    "    else:\n",
    "        kernel_h, kernel_w = kernel_size\n",
    "    if isinstance(stride, int):\n",
    "        stride_h, stride_w = stride, stride\n",
    "    else:\n",
    "        stride_h, stride_w = stride\n",
    "    \n",
    "    # 宽，(width - kernel_w + padding_w_left + padding_w_right) / stride_w + 1 == width\n",
    "    padding.append(((width-1)*stride_w - width + kernel_w) / 2)             # 整除，取下整\n",
    "    if ((width-1)*stride_w - width + kernel_w) % 2 == 0:\n",
    "        padding.append(((width-1)*stride_w - width + kernel_w) / 2)\n",
    "    else:\n",
    "        padding.append(((width-1)*stride_w - width + kernel_w) / 2 + 1)\n",
    "    # 高，也是类似\n",
    "    padding.append(((height-1)*stride_h - height + kernel_h) / 2)\n",
    "    if ((height-1)*stride_h - height + kernel_h) % 2 == 0:\n",
    "        padding.append(((height-1)*stride_h - height + kernel_h) / 2)\n",
    "    else:\n",
    "        padding.append(((height-1)*stride_h - height + kernel_h) / 2 + 1)\n",
    "    \n",
    "    return padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络中重复结构（卷积层）的构建函数，启发于VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_layer(in_channels, out_channels, kernel_size, stride, padding, batch_normalize=1, activation='leaky'):\n",
    "    '''\n",
    "    构建yolov1中的卷积层，形如pad->conv2d->batch_norm->activation function\n",
    "    \n",
    "    Parameters:\n",
    "    - in_channels, out_channels, kernel_size, stride, padding: 同nn.Conv2d\n",
    "    - batch_normalize: 是否要做批量归一化，默认要做\n",
    "    - activation: 激活函数种类，默认LeakyReLU\n",
    "    '''\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding))\n",
    "    if batch_normalize:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "    if activation=='leaky':\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络结构如图，图源自原论文，网络输入形如(batch_size, channel, height, width)\n",
    "\n",
    "<img src='./figs/yolov1_model.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中7x7代表将图片均匀划分成7x7个grid cell，每个grid cell负责判断是否有物体的中心点落在上面：\n",
    "\n",
    "<img src='./figs/yolov1_grid.png' style='zoom:50%'>\n",
    "\n",
    "每个grid对应一个长度为（5xB + class num）的向量：\n",
    "\n",
    "- B为每个grid负责回归的边界框个数；\n",
    "- 每个grid只能取B个中最好的一个作为预测值，即网络最多只能预测SxS个物体，论文中S=7，这也是YOLO-V1对小物体、密集物体效果不好的原因；\n",
    "- 5：每个边界框$(x_c, y_c, w, h, c)$，中心点位置、高宽、置信度；\n",
    "- class num：后面跟的ont hot向量，表示预测为类别i的概率（有疑问）；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v1(nn.Module):\n",
    "    '''\n",
    "    Yolo-v1的pytorch实现\n",
    "    \n",
    "    输入形状为448x448，B为每个grid预测的个数，Class_Num为分类数\n",
    "    '''\n",
    "    def __init__(self, B=2, Classes_Num=20):\n",
    "        super().__init__()\n",
    "        # 提前padding，保持各个块的卷积过后，形状不变；\n",
    "        # in:3x448x448, out:64x112x112\n",
    "        self.blk1 = nn.Sequential(\n",
    "            *create_conv_layer(3, 64, kernel_size=7, stride=2, padding=3),  # stride=2的conv和pool都是减高宽的\n",
    "            # nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=2),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:64x112x112, out:192x56x56\n",
    "        self.blk2 = nn.Sequential(\n",
    "            *create_conv_layer(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            # nn.BatchNorm2d(192),\n",
    "            # nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:192x56x56, out:512x28x28\n",
    "        self.blk3 = nn.Sequential(\n",
    "            *create_conv_layer(192, 128, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(256, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:512x28x28, out:1024x14x14\n",
    "        self.blk4 = nn.Sequential(\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 256, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(512, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        # in:1024x14x14, out:1024x14x14\n",
    "        self.blk4 = nn.Sequential(\n",
    "            *create_conv_layer(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 512, kernel_size=1, stride=1, padding=0),\n",
    "            *create_conv_layer(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        # in:1024x14x14, out:1024x7x7\n",
    "        self.blk5 = nn.Sequential(\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            *create_conv_layer(1024, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        # in:7x7x1024, out:7x7x30\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 1024, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 7 * 7 * (B*5 + Classes_Num)),\n",
    "            nn.Sigmoid()        # 增加sigmoid函数是为了将输出全部映射到(0,1)之间，因为如果出现负数或太大的数，后续计算loss会很麻烦\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 类GoogLeNet\n",
    "        # 也可换成resnet50，删除stage5后的全局池化和全连接层，增加一个带有空洞卷积的网络block（模仿detnet网络，增加感受野而不改变输出特征图大小）\n",
    "        x = self.blk1(x)\n",
    "        x = self.blk2(x)\n",
    "        x = self.blk3(x)\n",
    "        x = self.blk4(x)\n",
    "        # 后四层卷积\n",
    "        x = self.blk5(x)\n",
    "        # 为方便后处理，需要将输出构建成7x7x30，而不是30x7x7；为了符合直觉，需要做重排列将特征放在最后一维\n",
    "        # (batch_size, channel, height, width) -> (batch_size, height, width, channel)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # 展平+全连接层\n",
    "        x = self.fc(x)\n",
    "        # 重构\n",
    "        x = x.view((-1, 7, 7, (self.B*5 + self.Classes_Num)))\n",
    "\n",
    "    def initialize_params(self):\n",
    "        '''网络参数初始化'''\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "疑问：(x,y,w,h,c)和p是否需要做softmax？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function:\n",
    "\n",
    "<img src='./figs/yolov1_loss.png' style='zoom:60%;' />\n",
    "\n",
    "- 掩码：\n",
    "  - $\\mathbb{1}_{i}^{obj}$：有gt bbox的中心点落在grid $i$中；\n",
    "  - $\\mathbb{1}_{ij}^{obj}$：有gt bbox的中心点落在grid $i$中，且该grid回归的的B个bbox中，第$j$个bbox与该gt bbox的IoU最大；\n",
    "  - $\\mathbb{1}_{ij}^{noobj} == not \\ (\\mathbb{1}_{ij}^{obj})$；\n",
    "- 第一项为中心点定位误差；\n",
    "- 第二项为宽高定位误差：\n",
    "  - 求根号可使小的bbox对误差更敏感；\n",
    "- 第三、四项为confidence回归误差：\n",
    "  - $\\mathbb{1}_{ij}^{obj}==1$时（第三项），$\\hat{C}_i$为该grid回归的第j个bbox，与中心点落在该grid的gt bbox的IoU；\n",
    "  - $\\mathbb{1}_{ij}^{obj}==0$时（第四项），$\\hat{C}_i$为0；\n",
    "  - $C_i$为预测值；\n",
    "- 第五项为类别预测误差；\n",
    "- 权重：\n",
    "  - 物体检测问题，是一个典型的类别数目不均衡的问题。其中49个格点，含有物体的格点往往只有3、4个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的mAP不会太高，因为模型更倾向于不含有物体的格点。\n",
    "  - $\\lambda_{\\mathbb{coord}}$：使网络更重视$(x_c,y_c,w,h)$的预测；\n",
    "  - $\\lambda_{noobj}$：对不负责预测obj的confidence loss，赋予小的权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v1_loss(nn.Module):\n",
    "    '''\n",
    "    Yolo-v1的损失函数计算的pytorch实现\n",
    "\n",
    "    Parameters:\n",
    "    - img_shape: _size_2_t，[h, w]\n",
    "    - S: _size_2_t，表示一张图片被划分成了[高x宽]个grid，默认为7表示7x7\n",
    "    - B: int，一个grid回归多少个bbox\n",
    "    - Class_num: int，类别个数\n",
    "    - l_coord、l_noobj: 对应两个lambda\n",
    "    '''\n",
    "    def __init__(self, img_shape=448, S=7, B=2, Class_num=20, l_coord=5, l_noobj=0.5):\n",
    "        super().__init__()\n",
    "        # 图片的形状\n",
    "        if isinstance(img_shape, int):\n",
    "            self.img_h = img_shape\n",
    "            self.img_w = img_shape\n",
    "        elif isinstance(img_shape, list):\n",
    "            self.img_h = img_shape[0]\n",
    "            self.img_w = img_shape[1]\n",
    "        # 网格的个数形状\n",
    "        if isinstance(S, int):\n",
    "            self.S_h = S\n",
    "            self.S_w = S\n",
    "        elif isinstance(S, list):\n",
    "            self.S_h = S[0]\n",
    "            self.S_w = S[1]\n",
    "        self.grid_h = self.img_h / self.S_h     # 网格的高度和宽度\n",
    "        self.grid_w = self.img_w / self.S_w\n",
    "        self.B = B\n",
    "        self.Class_num = Class_num\n",
    "        self.l_coord = l_coord\n",
    "        self.l_noobj = l_noobj\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        '''\n",
    "        前向计算\n",
    "        - pred:  (batch_size, S_h, S_w, (B)*5+Class_num)，未经过预处理，仍然只是Yolo_v1输出的sigmoid\n",
    "        - gt:    (batch_size, S_h, S_w, 5+Class_num)，已经经过预处理，框成center形式，其中confidence代表1_i^{obj}，类别成one-hot\n",
    "        '''\n",
    "        # 定义三个计算损失的变量 正样本定位损失 样本置信度损失 样本类别损失\n",
    "        loss_coord = 0\n",
    "        loss_confidence = 0\n",
    "        loss_classes = 0\n",
    "        iou_sum = 0\n",
    "        object_num = 0\n",
    "\n",
    "        mseLoss = nn.MSELoss()\n",
    "        # pred的预处理\n",
    "        for i in range(self.B):\n",
    "            pred[:, :, :, i*5+0] = pred[:, :, :, i*5+0] * self.grid_w   # x_c，最大不能超过一个grid\n",
    "            pred[:, :, :, i*5+1] = pred[:, :, :, i*5+1] * self.grid_h   # y_c\n",
    "            pred[:, :, :, i*5+2] = pred[:, :, :, i*5+2] * self.img_w    # w，最大不能超过整张图片\n",
    "            pred[:, :, :, i*5+3] = pred[:, :, :, i*5+3] * self.img_h    # h\n",
    "        \n",
    "        # loss计算\n",
    "        # 其实也可以使用矩阵运算优化，但保险起见，还是用了循环\n",
    "        for batch in range(len(pred)):\n",
    "            for row in range(self.S_h):\n",
    "                for col in range(self.S_w):\n",
    "                    pred_ = pred[batch, row, col, :]\n",
    "                    gt_ = gt[batch, row, col, :]\n",
    "                    if gt_[4] == 0:\n",
    "                        # [row, col]处的grid，没有gt框中心落在这，故B个框都是负样本，只需要加置信度loss\n",
    "                        for i in range(self.B):\n",
    "                            loss_confidence += self.l_noobj * torch.pow(pred_[i*5 + 4], 2)\n",
    "                    else:\n",
    "                        # [row, col]处的grid，有gt框中心落在这\n",
    "                        object_num += 1\n",
    "                        # 分别计算回归的B个框与gt的IoU\n",
    "                        iou = torch.zeros(self.B)\n",
    "                        gt_bbox = utils.bbox_center_to_corner(gt_[:4])\n",
    "                        for i in range(self.B):\n",
    "                            pred_bbox = utils.bbox_center_to_corner(pred_[i*5:(i*5+4)])\n",
    "                            iou[i] = utils.IoU(pred_bbox, gt_bbox)\n",
    "                        # 取IoU最大的成为正样本，其它B-1个成为负样本\n",
    "                        val, idx = iou.topk(1)\n",
    "                        # 定位loss\n",
    "                        loss_coord += self.l_coord * (torch.pow(pred_[idx*5] - gt_[0], 2) + torch.pow(pred_[idx*5+1] - gt_[1], 2)) + \\\n",
    "                                      self.l_coord * (torch.pow(torch.sqrt(pred_[idx*5+2]) - torch.sqrt(gt_[2]), 2) + \\\n",
    "                                                      torch.pow(torch.sqrt(pred_[idx*5+3]) - torch.sqrt(gt_[3]), 2))\n",
    "                        # 置信度loss\n",
    "                        iou_sum += val\n",
    "                        for i in range(self.B):\n",
    "                            if i == idx:\n",
    "                                # 正样本\n",
    "                                loss_confidence += torch.pow(pred_[i*5 + 4] - val, 2)\n",
    "                            else:\n",
    "                                # 负样本\n",
    "                                loss_confidence += self.l_noobj * torch.pow(pred_[i*5 + 4], 2)\n",
    "                        # 类别预测loss\n",
    "                        gt_class = gt_[5:]\n",
    "                        pred_class = pred_[(self.B*5):]\n",
    "                        loss_classes += mseLoss(gt_class, pred_class)\n",
    "        loss_coord /= len(pred)\n",
    "        loss_confidence /= len(pred)\n",
    "        loss_classes /= len(pred)\n",
    "        loss = loss_coord + loss_confidence + loss_classes\n",
    "        return loss, loss_coord, loss_confidence, loss_classes, iou_sum, object_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、预测阶段后处理：非极大值抑制（NMS）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不应用于训练阶段，只应用于训练完成后，应用模型进行预测的阶段。\n",
    "\n",
    "非极大值抑制（Non-Maximum Suppression）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88474ca0ac5bd289cfc2b7cff5e070fc2eb64be0b001ce0011ec337ea9a55b21"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
