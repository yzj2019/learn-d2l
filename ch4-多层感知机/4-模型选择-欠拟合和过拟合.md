## 模型选择、欠拟合和过拟合

希望确定模型是真正发现了一种泛化的模式， 而不是简单地记住了数据。

将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting）， 用于对抗过拟合的技术称为正则化（regularization）。

### 1.训练误差和泛化误差

- 训练误差：模型在训练数据集上的误差；
- 泛化误差：模型应用在同样从原始样本的分布中抽取的无限多的数据样本时，模型误差的期望。

无法准确计算出泛化误差，只能将模型应用于一个独立的测试集，来估计泛化误差；该测试集由随机选取的、未曾在训练集中出现的数据样本构成。

### 2.模型选择

是用什么样的模型，超参数大小是多少。

#### 2.1验证数据集和测试数据集

- 验证数据集：用来评估模型好坏，每轮epoch都可以评估
  - 例如拿出50%的训练数据；
  - **不能用于训练，但可用于调超参数。**
- 测试数据集：
  - 只用一次，用于评价最终模型；
  - **不能用于调超参数。**
- 独立同分布假设：假设训练数据和测试数据都是**从相同的分布中独立提取的**。

终于懂了为什么分AB榜。

#### 2.2K-fold交叉验证

- 在没有足够多数据时使用

- 算法：

  - 将训练数据分割成K块

  - For i = 1,...,K

    使用第i块作为验证数据集，其余的作为训练数据集

  - 一共训练K次，报告K个验证集误差的平均

- 常用：K=5或10

### 3.欠拟合还是过拟合？

- 欠拟合：数据复杂，模型容量低；
- 过拟合：数据简单，模型容量高；

![](https://img0.baidu.com/it/u=930714196,2694626340&fm=26&fmt=auto)

对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。

#### 3.1模型容量

拟合各种函数的能力。

- 低容量模型难以拟合训练数据；
- 高容量模型可以记住所有训练数据

模型容量可以估计，但难以在不同种类算法之间比较；

给定模型种类，有两个主要因素：

- 参数的个数；
- 参数值的选择范围。

#### 3.2VC dimension

- 统计学习理论的一个核心思想；
- 对一个分类模型算法，VC维等价于一个最大的数据集的大小，使得不管如何给定标号，都存在一个本种类算法的模型来对它进行完美分类。
- 例如：
  - 2维输入的感知机，VC维=3（二维平面上3个点，能够用一根线分成2类）（但一根线不能做XOR）
  - N维输入的感知机，VC维=N+1；
- 深度学习中很少用：衡量不准+计算困难。

#### 3.3数据复杂度

- 多个重要因素：（直观印象）
  - 样本个数；
  - 每个样本的属性个数；
  - 时空结构；
  - 多样性。

### 4.总结

- 模型选择
  - 训练数据集：训练模型参数
  - 验证数据集：选择模型超参数
  - 非大数据集上通常用K-fold交叉验证
- 欠拟合和过拟合
  - 模型容量需要匹配数据复杂度，否则可能导致欠拟合/过拟合。
  - 统计机器学习，提供数学工具衡量模型复杂度；
  - 实际中一般靠观察训练误差和验证误差。