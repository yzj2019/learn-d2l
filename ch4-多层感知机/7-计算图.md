## 前向传播、反向传播和计算图

在本节中，我们将通过一些基本的数学和计算图， 深入探讨反向传播的细节。 首先，我们将重点放在带权重衰减（ $L_2$正则化）的单隐藏层多层感知机上。

- 前向传播：按顺序（从输入层到输出层）**计算和存储**神经网络中每层的结果；
- 计算图：前向计算中变量与计算的依赖关系，有向无环图(cfg)；
- 反向传播：根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络，利用前向传播的中间结果，**计算并存储**最终的标量值（一般为Loss）关于各层参数的偏导数。

在训练神经网络时，在初始化模型参数后，我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。注意，反向传播重复利用前向传播中存储的中间值，以避免重复计算。带来的影响之一是我们需要保留中间值，直到反向传播完成。这也是训练比单纯的预测需要更多的内存（显存）的原因之一。此外，这些中间值的大小与网络层的数量和批量的大小大致成正比。因此，使用更大的批量来训练更深层次的网络更容易导致内存不足（out of memory）错误。
