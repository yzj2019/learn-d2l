{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 锚框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标检测算法通常会在输入图像中采样大量的区域，然后判断这些区域中是否包含我们感兴趣的目标，并调整区域边界从而更准确地预测目标的真实边界框（ground-truth bounding box）。\n",
    "\n",
    "其中一种区域采样方法，以每个像素为中心，生成多个缩放比和宽高比（aspect ratio）不同的边界框。这些边界框被称为锚框（anchor box）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一类目标检测算法是基于锚框的：\n",
    "- 提出多个锚框；\n",
    "- 预测每个锚框里，是否含有相关注的物体；\n",
    "- 如果是，则预测从这个锚框到真实边缘框的偏移；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "import d2l\n",
    "\n",
    "torch.set_printoptions(2)  # 精简输出精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、生成多个锚框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法固定生成，或者根据图片来生成；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入图像高度是$h$，宽度是$w$，以图像的每个像素为中心，生成不同形状的锚框：\n",
    "- 中心位置、缩放比、宽高比，唯一确定一个锚框；\n",
    "- 缩放比（scale）$s\\in(0, 1]$，宽高比（aspect ratio）为$r>0$；\n",
    "- 则锚框的宽度为$ws\\sqrt{r}$，高度为$\\frac{hs}{\\sqrt{r}}$；\n",
    "\n",
    "要生成许多不同形状的锚框，需要预先设置的缩放比取值$s_1,...,s_n$和许多宽高比取值$r_1,...,r_m$：\n",
    "- 排列组合，则共$whmn$个锚框，太多；\n",
    "- 实践中，只考虑包含$s_1$或$r_1$的组合：$(s_1,r_1),...,(s_1,r_m),(s_2,r_1),...,(s_n,r_1)$；共$wh(n+m-1)$个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox_prior(data, sizes, ratios):\n",
    "    \"\"\"\n",
    "    指定输入图像、尺寸列表和宽高比列表，生成以每个像素为中心具有不同形状的锚框\n",
    "    \n",
    "    Parameters:\n",
    "    - data: 输入图像\n",
    "    - sizes: 尺寸列表\n",
    "    - ratios: 宽高比列表\n",
    "    \"\"\"\n",
    "    in_height, in_width = data.shape[-2:]\n",
    "    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n",
    "    boxes_per_pixel = (num_sizes + num_ratios - 1)\n",
    "    size_tensor = torch.tensor(sizes, device=device)\n",
    "    ratio_tensor = torch.tensor(ratios, device=device)\n",
    "\n",
    "    # 为了将锚点移动到像素的中心，需要设置偏移量。\n",
    "    # 因为一个像素的的高为1且宽为1，我们选择偏移我们的中心0.5\n",
    "    offset_h, offset_w = 0.5, 0.5\n",
    "    steps_h = 1.0 / in_height  # 在y轴上缩放步长，为了归一化到(0, 1]，方便后面的锚框高宽表示（不需要再乘图像的高宽了）\n",
    "    steps_w = 1.0 / in_width  # 在x轴上缩放步长\n",
    "\n",
    "    # 生成锚框的所有中心点\n",
    "    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n",
    "    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n",
    "    shift_y, shift_x = torch.meshgrid(center_h, center_w)\n",
    "    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n",
    "\n",
    "    # 生成“boxes_per_pixel”个高和宽，\n",
    "    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax)\n",
    "    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n",
    "                   * in_height / in_width  # 处理矩形输入\n",
    "    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n",
    "                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n",
    "    # 除以2来获得半高和半宽\n",
    "    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n",
    "                                        in_height * in_width, 1) / 2\n",
    "\n",
    "    # 每个中心点都将有“boxes_per_pixel”个锚框，\n",
    "    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n",
    "    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n",
    "                dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n",
    "    output = out_grid + anchor_manipulations\n",
    "    return output.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def show_bboxes(axes, bboxes, labels=None, colors=None):\n",
    "    \"\"\"显示所有边界框\"\"\"\n",
    "    def _make_list(obj, default_values=None):\n",
    "        if obj is None:\n",
    "            obj = default_values\n",
    "        elif not isinstance(obj, (list, tuple)):\n",
    "            obj = [obj]\n",
    "        return obj\n",
    "\n",
    "    labels = _make_list(labels)\n",
    "    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        color = colors[i % len(colors)]\n",
    "        rect = utils.bbox_corner_to_rect(bbox.detach().numpy(), color)\n",
    "        axes.add_patch(rect)\n",
    "        if labels and len(labels) > i:\n",
    "            text_color = 'k' if color == 'w' else 'w'\n",
    "            axes.text(rect.xy[0], rect.xy[1], labels[i],\n",
    "                      va='center', ha='center', fontsize=9, color=text_color,\n",
    "                      bbox=dict(facecolor=color, lw=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、IoU - 交并比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IoU（Intersection over Union）用于计算两个框之间的相似度\n",
    "  - 0对应无重叠，1对应重合；\n",
    "- 这是Jacquard杰卡德相似度的一个特殊情况：\n",
    "  - 给定两个集合A和B，$J(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$\n",
    "  - IoU为两个边界框，相交面积与相并面积之比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、在训练数据中标注锚框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "赋予锚框标号：\n",
    "- 每个锚框是一个训练样本；边界框指的是ground truth；\n",
    "- 将每个锚框，要么标注成背景，要么关联上一个最接近此锚框的真实边缘框；\n",
    "- 算法可能会生成大量的锚框：\n",
    "  - 会导致大量的负样本；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了训练目标检测模型，我们需要每个锚框的类别（class）和偏移量（offset）标签，其中前者是与锚框相关的对象的类别，后者是真实边界框相对于锚框的偏移量。 在预测时，我们为每个图像生成多个锚框，预测所有锚框的类别和偏移量，根据预测的偏移量调整它们的位置以获得预测的边界框，最后只输出符合特定条件的预测边界框。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1、将最接近的真实边缘框分配给锚框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./figs/1.jpg' style=\"zoom:20%;\" />\n",
    "\n",
    "- 每个锚框与每个边缘框算IoU值，生成锚框-边缘框的2d矩阵；\n",
    "- 每次取最大值并删除最大值所在行列，直到所有的边缘框都对应到一个锚框；此步中生成的全是正例；\n",
    "- 剩余的锚框（即剩余训练样本）可：\n",
    "  - 全部标注成“背景”，即全是负例，会导致大量负样本；\n",
    "  - 寻找与本锚框IoU最大的边界框，若值大于阈值（ *能不能做动态阈值？* ），则将该边界框assign给本锚框。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2、标注类别和偏移量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、使用非极大值抑制（NMS）来预测边界框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在预测时，我们先为图像生成多个锚框，再为这些锚框一一预测类别和偏移量。\n",
    "\n",
    "当有许多锚框时，可能会输出许多相似的具有明显重叠的锚框，都围绕着同一目标。 为了简化输出，我们可以使用非极大值抑制（non-maximum suppression，NMS）合并属于同一目标的类似的锚框。\n",
    "\n",
    "在同一张图像中，所有预测的非背景锚框都按置信度降序排序，以生成列表 L 。然后我们通过以下步骤操作排序列表 L ：\n",
    "- 选中 L 中非基准的、最大置信度的锚框B，加入基准；\n",
    "- 去除所有其它和B的IoU值大于$\\epsilon$的非基准锚框；\n",
    "- 重复上述过程，直到 L 中都为基准；此时 L 中所锚框两两之间的IoU小于$\\epsilon$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一类目标检测算法基于锚框来预测；\n",
    "- 首先生成大量锚框，并赋予标号，每个锚框作为一个样本进行训练；\n",
    "- 在预测时，使用NMS来去掉冗余的预测。"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88474ca0ac5bd289cfc2b7cff5e070fc2eb64be0b001ce0011ec337ea9a55b21"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
